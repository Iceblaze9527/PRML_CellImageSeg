{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "import numpy as np\n",
    "\n",
    "import DG\n",
    "from UNet import UNet\n",
    "import Oper\n",
    "from Stats import print_data\n",
    "import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### paths\n",
    "train_path = 'dataset1/train/'\n",
    "gt_path = 'dataset1/train_GT/SEG'\n",
    "test_path = 'dataset1/test/'\n",
    "result_path = 'dataset1/test_RES/'\n",
    "save_path = 'saved_models/'##\n",
    "stats_path = 'stats/'##\n",
    "   \n",
    "### U-Net Params\n",
    "in_channels=1 \n",
    "n_classes=2\n",
    "depth=3\n",
    "wf=6 \n",
    "padding=True\n",
    "batch_norm=False\n",
    "up_mode='upconv'\n",
    "#### Param Notes\n",
    "\n",
    "\"\"\"\n",
    "Args:\n",
    "    in_channels (int): number of input channels\n",
    "    n_classes (int): number of output channels\n",
    "    depth (int): depth of the network\n",
    "    wf (int): number of filters in the first layer is 2**wf\n",
    "    padding (bool): if True, apply padding such that the input shape\n",
    "                    is the same as the output.\n",
    "                    This may introduce artifacts\n",
    "    batch_norm (bool): Use BatchNorm after layers with an\n",
    "                       activation function\n",
    "    up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                   'upconv' will use transposed convolutions for\n",
    "                   learned upsampling.\n",
    "                   'upsample' will use bilinear upsampling.\n",
    "\"\"\"\n",
    "\n",
    "### Model Running Params\n",
    "epochs = 16\n",
    "pad = 6\n",
    "train_ratio = 0.8\n",
    "\n",
    "#### optim Params\n",
    "optim_name = 'Adam'\n",
    "lr = 1e-5\n",
    "momentum = 0.99#for SGD\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-08\n",
    "weight_decay = 0\n",
    "\n",
    "#### loss function Params\n",
    "loss_func='cross_entropy'\n",
    "gamma = 0\n",
    "alpha = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### exp specific params\n",
    "save_path = save_path + '46_all_fl_best_0.99.tar'\n",
    "stats_path = stats_path + '46_all_fl_best_0.99'\n",
    "\n",
    "loss_func = 'focal_loss'\n",
    "depth = 4\n",
    "wf = 6\n",
    "\n",
    "train_ratio = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix backend\n",
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed) \n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    if torch.cuda.is_available():\n",
    "        print('GPU is available.')\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        print('GPU is not available. Use CPU instead.')\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    #数据变换\n",
    "    tr_ori = tr.Compose([\n",
    "        tr.ToPILImage(),\n",
    "        tr.Grayscale(1),\n",
    "        tr.Pad(pad),\n",
    "        tr.ToTensor()\n",
    "    ])\n",
    "    #原数据构成的数据集\n",
    "    dataset_ori = DG.DatasetGen(train_path, gt_path, tr_ori)\n",
    "    #水平翻转\n",
    "    dataset_h = DG.DatasetHGen(train_path, gt_path, tr_ori)\n",
    "    #垂直翻转\n",
    "    dataset_v = DG.DatasetVGen(train_path, gt_path, tr_ori) \n",
    "    #水平+垂直翻转（旋转180度）\n",
    "    dataset_hv = DG.DatasetHVGen(train_path, gt_path, tr_ori) \n",
    "    #逆时针旋转90度\n",
    "    dataset_r90 = DG.DatasetR90Gen(train_path, gt_path, tr_ori)\n",
    "    #逆时针旋转270度\n",
    "    dataset_r270 = DG.DatasetR270Gen(train_path, gt_path, tr_ori) \n",
    "    #变形，采用U-Net原文的参数\n",
    "    dataset_ed = DG.DatasetEDGen(train_path, gt_path, tr_ori, 10, 3, [3, 0])\n",
    "    #转置\n",
    "    dataset_tp = DG.DatasetTPGen(train_path, gt_path, tr_ori)\n",
    "    #另一种转置\n",
    "    dataset_sktp = DG.DatasetSTPGen(train_path, gt_path, tr_ori)  \n",
    "    #合并数据集\n",
    "    dataset = ConcatDataset([dataset_ori, dataset_h, dataset_v, \n",
    "                             dataset_hv, dataset_r90, dataset_r270, \n",
    "                             dataset_ed, dataset_tp, dataset_sktp])\n",
    "    \n",
    "    train_size = int(np.floor(train_ratio * (dataset.__len__())))\n",
    "    val_size = dataset.__len__() - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    model = UNet(\n",
    "                in_channels=in_channels, \n",
    "                n_classes=n_classes, \n",
    "                depth=depth, \n",
    "                wf=wf, \n",
    "                padding=padding, \n",
    "                batch_norm=batch_norm, \n",
    "                up_mode=up_mode).to(device)\n",
    "    \n",
    "    if optim_name == 'Adam':\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "    elif optim_name == 'SGD':\n",
    "        optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    \n",
    "    stats = Oper.run_model(\n",
    "                model = model, \n",
    "                optim = optim,\n",
    "                train_loader = train_loader, \n",
    "                val_loader = val_loader, \n",
    "                device = device,\n",
    "                save_path = save_path,\n",
    "                train_size = train_size,\n",
    "                val_size = val_size,\n",
    "                epochs = epochs,\n",
    "                pad = pad,\n",
    "                lr = lr, \n",
    "                betas = betas, \n",
    "                eps = eps, \n",
    "                weight_decay = weight_decay,\n",
    "                loss_func=loss_func,\n",
    "                gamma = gamma, \n",
    "                alpha = alpha)\n",
    "    \n",
    "    print_data(epochs = epochs, stats = stats, stats_path = stats_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## if this is the best result\n",
    "best_model = UNet(\n",
    "            in_channels=in_channels, \n",
    "            n_classes=n_classes, \n",
    "            depth=depth, \n",
    "            wf=wf, \n",
    "            padding=padding, \n",
    "            batch_norm=batch_norm, \n",
    "            up_mode=up_mode)\n",
    "\n",
    "Output.test_out(best_model, save_path, test_path, result_path, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}