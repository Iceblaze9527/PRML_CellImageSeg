{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "import numpy as np\n",
    "\n",
    "import DG\n",
    "from UNet import UNet\n",
    "import Oper\n",
    "from Stats import print_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'dataset1/train/'\n",
    "gt_path = 'dataset1/train_GT/SEG'\n",
    "test_path = 'dataset1/test/'\n",
    "result_path = 'dataset1/test_RES/'\n",
    "save_path = 'saved_models/'##\n",
    "stats_path = 'stats/'##\n",
    "\n",
    "in_channels=1 \n",
    "n_classes=2\n",
    "depth=4\n",
    "wf=6\n",
    "padding=True\n",
    "batch_norm=False\n",
    "up_mode='upconv'\n",
    "\n",
    "epochs = 16\n",
    "pad = 6\n",
    "train_ratio = 0.9\n",
    "\n",
    "#### optim Params\n",
    "optim_name = 'Adam'\n",
    "lr = 1e-5\n",
    "momentum = 0.99#for SGD\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-08\n",
    "weight_decay = 0\n",
    "\n",
    "#### loss function Params\n",
    "loss_func='cross_entropy'\n",
    "gamma = 0\n",
    "alpha = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = save_path + '46_all_fl_best_0.99.tar'\n",
    "save_path = save_path + '46_all_fl_best_0.99.tar'\n",
    "stats_path = stats_path + '46_all_fl_best_0.99'\n",
    "\n",
    "depth=4\n",
    "wf=6\n",
    "loss_func = 'focal_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = UNet(\n",
    "            in_channels=in_channels, \n",
    "            n_classes=n_classes, \n",
    "            depth=depth, \n",
    "            wf=wf, \n",
    "            padding=padding, \n",
    "            batch_norm=batch_norm, \n",
    "            up_mode=up_mode)\n",
    "\n",
    "optim = torch.optim.Adam(best_model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path)##\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optim = optim.load_state_dict(checkpoint['optim_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "epochs = 16\n",
    "print(epoch)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('GPU is available.')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('GPU is not available. Use CPU instead.')\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ori = tr.Compose([\n",
    "    tr.ToPILImage(),\n",
    "    tr.Grayscale(1),\n",
    "    tr.Pad(pad),\n",
    "    tr.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_ori = DG.DatasetGen(train_path, gt_path, tr_ori)\n",
    "\n",
    "dataset_h = DG.DatasetHGen(train_path, gt_path, tr_ori)\n",
    "dataset_v = DG.DatasetVGen(train_path, gt_path, tr_ori) \n",
    "dataset_hv = DG.DatasetHVGen(train_path, gt_path, tr_ori) \n",
    "\n",
    "dataset_r90 = DG.DatasetR90Gen(train_path, gt_path, tr_ori)\n",
    "dataset_r270 = DG.DatasetR270Gen(train_path, gt_path, tr_ori) \n",
    "dataset_ed = DG.DatasetEDGen(train_path, gt_path, tr_ori, 10, 3, [3, 0]) \n",
    "\n",
    "dataset = ConcatDataset([dataset_ori, dataset_h, dataset_v, \n",
    "                         dataset_hv, dataset_r90, dataset_r270, dataset_ed])\n",
    "train_size = int(np.floor(train_ratio * (dataset.__len__())))\n",
    "val_size = dataset.__len__() - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "stats = Oper.run_model(\n",
    "            model = best_model, \n",
    "            optim = optim,\n",
    "            train_loader = train_loader, \n",
    "            val_loader = val_loader, \n",
    "            device = device,\n",
    "            save_path = save_path,\n",
    "            train_size = train_size,\n",
    "            val_size = val_size,\n",
    "            epochs = epochs,\n",
    "            pad = pad,\n",
    "            lr = lr, \n",
    "            betas = betas, \n",
    "            eps = eps, \n",
    "            weight_decay = weight_decay,\n",
    "            loss_func=loss_func,\n",
    "            gamma = gamma, \n",
    "            alpha = alpha)\n",
    "\n",
    "print_data(epochs = epochs, stats = stats, stats_path = stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}